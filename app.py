import warnings
warnings.filterwarnings('ignore', category=UserWarning)

import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta
from src.data_processor import DataProcessor
from src.text_analyzer import SentimentAnalyzer, KeywordAnalyzer, TopicAnalyzer, InsightAnalyzer
from src.visualizer import Visualizer, SentimentVisualizer, KeywordVisualizer, TopicVisualizer, InsightVisualizer

def display_statistics(stats: dict):
    """æ˜¾ç¤ºç»Ÿè®¡æŒ‡æ ‡"""
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("æ€»è¯„è®ºæ•°", stats['total_reviews'])
    with col2:
        st.metric("å¹³å‡è¯„åˆ†", stats['average_rating'])
    with col3:
        st.metric("æœ€è¿‘30å¤©è¯„è®ºæ•°", 
                 sum(count for date, count in stats['daily_reviews'].items() 
                     if datetime.strptime(str(date), '%Y-%m-%d').date() > 
                     datetime.now().date() - timedelta(days=30)))

def plot_rating_distribution(stats: dict):
    """ç»˜åˆ¶è¯„åˆ†åˆ†å¸ƒå›¾"""
    df = pd.DataFrame(list(stats['rating_distribution'].items()),
                     columns=['è¯„åˆ†', 'æ•°é‡'])
    fig = px.bar(df, x='è¯„åˆ†', y='æ•°é‡',
                 title='è¯„åˆ†åˆ†å¸ƒ',
                 labels={'è¯„åˆ†': 'è¯„åˆ†', 'æ•°é‡': 'è¯„è®ºæ•°é‡'})
    st.plotly_chart(fig)

def plot_daily_reviews(stats: dict):
    """ç»˜åˆ¶æ¯æ—¥è¯„è®ºæ•°é‡è¶‹åŠ¿å›¾"""
    df = pd.DataFrame(list(stats['daily_reviews'].items()),
                     columns=['æ—¥æœŸ', 'æ•°é‡'])
    fig = px.line(df, x='æ—¥æœŸ', y='æ•°é‡',
                  title='è¯„è®ºæ•°é‡è¶‹åŠ¿',
                  labels={'æ—¥æœŸ': 'æ—¥æœŸ', 'æ•°é‡': 'è¯„è®ºæ•°é‡'})
    st.plotly_chart(fig)

def show_keyword_analysis(df: pd.DataFrame, language: str):
    """
    æ˜¾ç¤ºå…³é”®è¯åˆ†æé¡µé¢
    
    Args:
        df: æ•°æ®æ¡†
        language: æ–‡æœ¬è¯­è¨€
    """
    st.header("å…³é”®è¯åˆ†æ")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    keyword_analyzer = KeywordAnalyzer(language)
    keyword_visualizer = KeywordVisualizer()
    
    # åˆ†æè®¾ç½®
    col1, col2 = st.columns(2)
    with col1:
        top_n = st.slider("æ˜¾ç¤ºå…³é”®è¯æ•°é‡", 5, 50, 20)
    with col2:
        time_window = st.selectbox(
            "æ—¶é—´çª—å£",
            options=[("æ—¥", "D"), ("å‘¨", "W"), ("æœˆ", "M")],
            format_func=lambda x: x[0],
            index=1
        )[1]
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["è¯äº‘å›¾", "å…³é”®è¯è¶‹åŠ¿", "è¯„åˆ†å…³é”®è¯å¯¹æ¯”"])
    
    with tab1:
        st.subheader("è¯äº‘åˆ†æ")
        if st.button("ç”Ÿæˆè¯äº‘", key="generate_wordcloud"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆè¯äº‘..."):
                # æå–å…³é”®è¯
                texts = df['review_text'].tolist()
                keywords = keyword_analyzer.extract_keywords(texts, top_n)
                
                # ç”Ÿæˆè¯äº‘å›¾
                st.plotly_chart(
                    keyword_visualizer.create_wordcloud(keywords),
                    use_container_width=True
                )
    
    with tab2:
        st.subheader("å…³é”®è¯è¶‹åŠ¿åˆ†æ")
        if st.button("åˆ†æè¶‹åŠ¿", key="analyze_trends"):
            with st.spinner("æ­£åœ¨åˆ†æè¶‹åŠ¿..."):
                # è·å–æ•´ä½“å…³é”®è¯
                all_keywords = keyword_analyzer.extract_keywords(
                    df['review_text'].tolist(),
                    top_n=10  # è¿½è¸ªå‰10ä¸ªå…³é”®è¯
                )
                
                # è®¡ç®—è¶‹åŠ¿
                trend_df = keyword_analyzer.calculate_keyword_trends(
                    df,
                    list(all_keywords.keys()),
                    time_window
                )
                
                # æ˜¾ç¤ºè¶‹åŠ¿å›¾
                st.plotly_chart(
                    keyword_visualizer.create_keyword_trend_chart(trend_df),
                    use_container_width=True
                )
    
    with tab3:
        st.subheader("è¯„åˆ†å…³é”®è¯å¯¹æ¯”")
        if st.button("åˆ†æè¯„åˆ†å…³é”®è¯", key="analyze_rating_keywords"):
            with st.spinner("æ­£åœ¨åˆ†æè¯„åˆ†å…³é”®è¯..."):
                # æŒ‰è¯„åˆ†æå–å…³é”®è¯
                keywords_by_rating = keyword_analyzer.extract_keywords_by_rating(
                    df,
                    top_n=10
                )
                
                # æ˜¾ç¤ºå¯¹æ¯”å›¾
                st.plotly_chart(
                    keyword_visualizer.create_rating_keyword_comparison(keywords_by_rating),
                    use_container_width=True
                )
                
                # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("##### é«˜åˆ†è¯„ä»·å¸¸è§å…³é”®è¯")
                    for word, weight in keywords_by_rating['positive'].items():
                        st.write(f"- {word}: {weight:.4f}")
                
                with col2:
                    st.markdown("##### ä½åˆ†è¯„ä»·å¸¸è§å…³é”®è¯")
                    for word, weight in keywords_by_rating['negative'].items():
                        st.write(f"- {word}: {weight:.4f}")

def show_topic_analysis(df: pd.DataFrame, language: str):
    """
    æ˜¾ç¤ºä¸»é¢˜åˆ†æé¡µé¢
    
    Args:
        df: æ•°æ®æ¡†
        language: æ–‡æœ¬è¯­è¨€
    """
    st.header("ä¸»é¢˜èšç±»åˆ†æ")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    topic_analyzer = TopicAnalyzer(language)
    topic_visualizer = TopicVisualizer()
    
    # é…ç½®åŒº
    col1, col2, col3 = st.columns(3)
    with col1:
        n_topics = st.slider("ä¸»é¢˜æ•°é‡", 3, 10, 5)
    with col2:
        method = st.selectbox(
            "åˆ†ææ–¹æ³•", 
            options=[("LDAä¸»é¢˜æ¨¡å‹", "lda"), ("KMeansèšç±»", "kmeans")],
            format_func=lambda x: x[0],
            index=0
        )[1]
    with col3:
        time_window = st.selectbox(
            "æ—¶é—´çª—å£",
            options=[("æ—¥", "D"), ("å‘¨", "W"), ("æœˆ", "M")],
            format_func=lambda x: x[0],
            index=1
        )[1]
    
    # åˆ†æç»“æœå±•ç¤º
    tab1, tab2, tab3, tab4 = st.tabs([
        "ä¸»é¢˜åˆ†å¸ƒ",
        "ä¸»é¢˜ç½‘ç»œ",
        "ä¸»é¢˜çƒ­åŠ›å›¾",
        "ä¸»é¢˜è¶‹åŠ¿"
    ])
    
    if st.button("å¼€å§‹åˆ†æ", key="start_topic_analysis"):
        with st.spinner("æ­£åœ¨è¿›è¡Œä¸»é¢˜åˆ†æ..."):
            # è·å–æ–‡æœ¬æ•°æ®
            texts = df['review_text'].tolist()
            
            # æ‰§è¡Œä¸»é¢˜åˆ†æ
            topic_results = topic_analyzer.analyze_topics(
                texts,
                n_topics=n_topics,
                method=method
            )
            
            if topic_results:
                # ä¸»é¢˜åˆ†å¸ƒ
                with tab1:
                    st.subheader("ä¸»é¢˜åˆ†å¸ƒåˆ†æ")
                    st.plotly_chart(
                        topic_visualizer.create_topic_distribution(topic_results),
                        use_container_width=True
                    )
                    
                    # æ˜¾ç¤ºä¸»é¢˜å…³é”®è¯
                    st.subheader("ä¸»é¢˜å…³é”®è¯")
                    for i, keywords in enumerate(topic_results['topics']):
                        with st.expander(f"ä¸»é¢˜ {i+1}"):
                            st.write("å…³é”®è¯ï¼š" + ", ".join(keywords))
                            if 'example_docs' in topic_results:
                                st.write("ç¤ºä¾‹æ–‡æ¡£ï¼š")
                                for doc in topic_results['example_docs'].get(i, []):
                                    st.markdown(f"> {doc}")
                
                # ä¸»é¢˜ç½‘ç»œ
                with tab2:
                    st.subheader("ä¸»é¢˜-å…³é”®è¯ç½‘ç»œå›¾")
                    st.plotly_chart(
                        topic_visualizer.create_topic_network(topic_results),
                        use_container_width=True
                    )
                
                # ä¸»é¢˜çƒ­åŠ›å›¾
                with tab3:
                    st.subheader("ä¸»é¢˜åˆ†å¸ƒçƒ­åŠ›å›¾")
                    if 'topic_distribution' in topic_results:
                        topic_dist_df = pd.DataFrame(
                            topic_results['topic_distribution'],
                            columns=[f"ä¸»é¢˜{i+1}" for i in range(n_topics)]
                        )
                        st.plotly_chart(
                            topic_visualizer.create_topic_heatmap(topic_dist_df),
                            use_container_width=True
                        )
                    else:
                        st.info("å½“å‰åˆ†ææ–¹æ³•ä¸æ”¯æŒä¸»é¢˜åˆ†å¸ƒçƒ­åŠ›å›¾")
                
                # ä¸»é¢˜è¶‹åŠ¿
                with tab4:
                    st.subheader("ä¸»é¢˜è¶‹åŠ¿åˆ†æ")
                    trend_df = topic_analyzer.get_topic_trends(
                        df,
                        topic_results['document_topics'],
                        time_window
                    )
                    
                    if not trend_df.empty:
                        st.plotly_chart(
                            topic_visualizer.create_topic_trend(trend_df),
                            use_container_width=True
                        )
                    else:
                        st.warning("æ— æ³•ç”Ÿæˆä¸»é¢˜è¶‹åŠ¿å›¾ï¼Œå¯èƒ½æ˜¯æ•°æ®é‡ä¸è¶³")
                
                # ä¸‹è½½åˆ†æç»“æœ
                if st.download_button(
                    "ä¸‹è½½åˆ†æç»“æœ",
                    data=pd.DataFrame({
                        'text': texts,
                        'topic': topic_results['document_topics']
                    }).to_csv(index=False),
                    file_name="topic_analysis_results.csv",
                    mime="text/csv"
                ):
                    st.success("åˆ†æç»“æœå·²ä¸‹è½½")

def show_insights_analysis(df: pd.DataFrame, language: str):
    """
    æ˜¾ç¤ºè¯„è®ºæ´å¯Ÿåˆ†æé¡µé¢
    
    Args:
        df: æ•°æ®æ¡†
        language: æ–‡æœ¬è¯­è¨€
    """
    st.header("è¯„è®ºæ·±åº¦æ´å¯Ÿ")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    insight_analyzer = InsightAnalyzer(language)
    insight_visualizer = InsightVisualizer()
    
    if st.button("å¼€å§‹åˆ†æ", key="start_insight_analysis"):
        with st.spinner("æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ..."):
            # æå–æ´å¯Ÿ
            insights = insight_analyzer.extract_insights(df)
            
            if insights:
                # æ˜¾ç¤ºå¼‚å¸¸æ£€æµ‹ç»“æœ
                st.subheader("å¼‚å¸¸è¯„è®ºæ£€æµ‹")
                
                # æ˜¾ç¤ºå¼‚å¸¸ç»Ÿè®¡
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        "å¼‚å¸¸è¯„è®ºæ•°é‡",
                        insights['anomalies']['total']
                    )
                with col2:
                    st.metric(
                        "å¼‚å¸¸è¯„è®ºæ¯”ä¾‹",
                        f"{insights['anomalies']['total']/len(df):.1%}"
                    )
                
                # æ˜¾ç¤ºå¼‚å¸¸æ•£ç‚¹å›¾
                st.plotly_chart(
                    insight_visualizer.create_anomaly_scatter(df),
                    use_container_width=True
                )
                
                # æ˜¾ç¤ºç›¸å…³æ€§åˆ†æ
                st.subheader("ç›¸å…³æ€§åˆ†æ")
                if insights.get('correlations'):
                    st.metric(
                        "è¯„åˆ†-æƒ…æ„Ÿç›¸å…³æ€§",
                        f"{insights['correlations']['correlation']:.2f}"
                    )
                    st.metric(
                        "è¯„åˆ†-æƒ…æ„Ÿä¸€è‡´æ€§",
                        f"{insights['correlations']['consistency']:.1%}"
                    )

def main():
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="é¡¾å®¢è¯„è®ºåˆ†æç³»ç»Ÿ",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    # é¡µé¢æ ‡é¢˜
    st.title("é¡¾å®¢è¯„è®ºåˆ†æç³»ç»Ÿ")
    st.markdown("### æ™ºèƒ½åˆ†ææ‚¨çš„é¡¾å®¢è¯„è®ºæ•°æ®")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    data_processor = DataProcessor()
    
    # ä¾§è¾¹
    with st.sidebar:
        st.header("é…ç½®é€‰é¡¹")
        language = st.selectbox(
            "é€‰æ‹©è¯„è®ºè¯­è¨€",
            ["ä¸­æ–‡", "è‹±æ–‡", "åŒè¯­"]
        )
        
        analysis_options = st.multiselect(
            "é€‰æ‹©åˆ†æç»´åº¦",
            ["æƒ…æ„Ÿåˆ†æ", "å…³é”®è¯æå–", "ä¸»é¢˜èšç±»", "è¯„åˆ†ç»Ÿè®¡"],
            default=["æƒ…æ„Ÿåˆ†æ", "å…³é”®è¯æå–"]
        )
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    tabs = st.tabs(["æ•°æ®ä¸Šä¼ ", "æƒ…æ„Ÿåˆ†æ", "å…³é”®è¯åˆ†æ", "ä¸»é¢˜åˆ†æ", "æ´å¯Ÿåˆ†æ", "å¯è§†åŒ–å±•ç¤º"])
    
    with tabs[0]:
        st.header("æ•°æ®ä¸Šä¼ ")
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶",
            type=["csv", "xlsx"]
        )
        
        if uploaded_file is not None:
            try:
                # æ˜¾ç¤ºè¿›åº¦æ¡
                with st.spinner('æ­£åœ¨å¤„ç†æ•°æ®...'):
                    # åŠ è½½æ•°æ®
                    if uploaded_file.name.endswith('.csv'):
                        df = pd.read_csv(uploaded_file)
                    else:
                        df = pd.read_excel(uploaded_file)
                    
                    # æ•°æ®é¢„è§ˆ
                    st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
                    st.subheader("æ•°æ®é¢„è§ˆ")
                    st.dataframe(df.head())
                    
                    # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
                    st.subheader("æ•°æ®åŸºæœ¬ä¿¡æ¯")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("æ•°æ®ç»´åº¦:", df.shape)
                    with col2:
                        st.write("åˆ—å:", list(df.columns))
                    
                    # æ•°æ®ç­›é€‰
                    st.subheader("æ•°æ®ç­›é€‰")
                    col1, col2 = st.columns(2)
                    with col1:
                        start_date = st.date_input(
                            "å¼€å§‹æ—¥æœŸ",
                            min(df['timestamp'].dt.date)
                        )
                    with col2:
                        end_date = st.date_input(
                            "ç»“æŸæ—¥æœŸ",
                            max(df['timestamp'].dt.date)
                        )
                    
                    # å¤„ç†æ•°æ®
                    data_processor.data = df
                    filtered_df = data_processor.filter_by_date_range(
                        datetime.combine(start_date, datetime.min.time()),
                        datetime.combine(end_date, datetime.max.time())
                    )
                    
                    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                    stats = data_processor.calculate_statistics()
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    st.subheader("ç»Ÿè®¡ä¿¡æ¯")
                    display_statistics(stats)
                    
                    # æ˜¾ç¤ºå›¾è¡¨
                    col1, col2 = st.columns(2)
                    with col1:
                        plot_rating_distribution(stats)
                    with col2:
                        plot_daily_reviews(stats)
                    
            except Exception as e:
                st.error(f"æ•°æ®å¤„ç†é”™è¯¯ï¼š{str(e)}")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    sentiment_analyzer = SentimentAnalyzer(language)
    sentiment_visualizer = SentimentVisualizer()
    
    with tabs[1]:
        st.header("æƒ…æ„Ÿåˆ†æ")
        if 'df' not in locals():
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        else:
            try:
                # åˆå§‹åŒ–åˆ†æå™¨
                sentiment_analyzer = SentimentAnalyzer(language)
                sentiment_visualizer = SentimentVisualizer()
                
                # æƒ…æ„Ÿåˆ†æè®¾ç½®
                st.subheader("åˆ†æè®¾ç½®")
                batch_size = st.slider("æ‰¹å¤„ç†å¤§å°", 16, 64, 32)
                
                if st.button("å¼€å§‹åˆ†æ"):
                    # æ˜¾ç¤ºè¿›åº¦æ¡
                    progress_text = st.empty()
                    progress_bar = st.progress(0)
                    
                    # æ‰§è¡Œæƒ…æ„Ÿåˆ†æ
                    texts = filtered_df['review_text'].tolist()
                    sentiment_results = sentiment_analyzer.analyze_batch(
                        texts,
                        batch_size=batch_size
                    )
                    
                    # æ›´æ–°DataFrame
                    filtered_df['sentiment'] = [r['sentiment'] for r in sentiment_results]
                    filtered_df['confidence'] = [r['confidence'] for r in sentiment_results]
                    
                    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                    sentiment_stats = sentiment_analyzer.get_sentiment_stats(sentiment_results)
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.subheader("åˆ†æç»“æœ")
                    
                    # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric(
                            "æ­£é¢è¯„è®ºæ¯”ä¾‹",
                            f"{sentiment_stats['sentiment_distribution'].get('æ­£é¢', 0) / len(sentiment_results):.1%}"
                        )
                    with col2:
                        st.metric(
                            "è´Ÿé¢è¯„è®ºæ¯”ä¾‹",
                            f"{sentiment_stats['sentiment_distribution'].get('è´Ÿé¢', 0) / len(sentiment_results):.1%}"
                        )
                    with col3:
                        st.metric(
                            "å¹³å‡ç½®ä¿¡åº¦",
                            f"{sentiment_stats['average_confidence']:.2f}"
                        )
                    
                    # æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ
                    st.plotly_chart(
                        sentiment_visualizer.create_sentiment_distribution(sentiment_results)
                    )
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.plotly_chart(
                            sentiment_visualizer.create_sentiment_trend(filtered_df)
                        )
                    with col2:
                        st.plotly_chart(
                            sentiment_visualizer.create_rating_sentiment_comparison(filtered_df)
                        )
                    
                    # æ˜¾ç¤ºå…¸å‹è¯„è®º
                    st.subheader("å…¸å‹è¯„è®ºç¤ºä¾‹")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("##### å…¸å‹æ­£é¢è¯„è®º")
                        for comment in sentiment_stats['typical_positive']:
                            st.markdown(f"""
                            > {comment['text']}  
                            > ç½®ä¿¡åº¦ï¼š{comment['confidence']:.2f}
                            """)
                    
                    with col2:
                        st.markdown("##### å…¸å‹è´Ÿé¢è¯„è®º")
                        for comment in sentiment_stats['typical_negative']:
                            st.markdown(f"""
                            > {comment['text']}  
                            > ç½®ä¿¡åº¦ï¼š{comment['confidence']:.2f}
                            """)
                    
            except Exception as e:
                st.error(f"æƒ…æ„Ÿåˆ†æè¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")
    
    with tabs[2]:
        if 'df' not in locals():
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        else:
            show_keyword_analysis(filtered_df, language)
    
    with tabs[3]:
        if 'df' not in locals():
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        else:
            show_topic_analysis(filtered_df, language)
    
    with tabs[4]:
        if 'df' not in locals():
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        else:
            show_insights_analysis(filtered_df, language)
    
    with tabs[5]:
        st.header("å¯è§†åŒ–å±•ç¤º")
        if 'df' not in locals():
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        else:
            st.subheader("è‡ªå®šä¹‰å›¾è¡¨")
            # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªå®šä¹‰å¯è§†åŒ–çš„ä»£ç 

if __name__ == "__main__":
    main() 