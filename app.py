import warnings
warnings.filterwarnings('ignore', category=UserWarning)

import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta
from src.data_processor import DataProcessor
from src.text_analyzer import SentimentAnalyzer, KeywordAnalyzer, TopicAnalyzer, InsightAnalyzer
from src.visualizer import Visualizer, SentimentVisualizer, KeywordVisualizer, TopicVisualizer, InsightVisualizer

from utils.jieba_config import initialize_jieba
import plotly.express as px
import plotly.graph_objects as go

def display_statistics(stats: dict):
    """æ˜¾ç¤ºç»Ÿè®¡æŒ‡æ ‡"""
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("æ€»è¯„è®ºæ•°", stats['total_reviews'])
    with col2:
        st.metric("å¹³å‡è¯„åˆ†", stats['average_rating'])
    with col3:
        st.metric("æœ€è¿‘30å¤©è¯„è®ºæ•°", 
                 sum(count for date, count in stats['daily_reviews'].items() 
                     if datetime.strptime(str(date), '%Y-%m-%d').date() > 
                     datetime.now().date() - timedelta(days=30)))

def plot_rating_distribution(stats: dict):
    """ç»˜åˆ¶è¯„åˆ†åˆ†å¸ƒå›¾"""
    df = pd.DataFrame(list(stats['rating_distribution'].items()),
                     columns=['è¯„åˆ†', 'æ•°é‡'])
    fig = px.bar(df, x='è¯„åˆ†', y='æ•°é‡',
                 title='è¯„åˆ†åˆ†å¸ƒ',
                 labels={'è¯„åˆ†': 'è¯„åˆ†', 'æ•°é‡': 'è¯„è®ºæ•°é‡'})
    st.plotly_chart(fig)

def plot_daily_reviews(stats: dict):
    """ç»˜åˆ¶æ¯æ—¥è¯„è®ºæ•°é‡è¶‹åŠ¿å›¾"""
    df = pd.DataFrame(list(stats['daily_reviews'].items()),
                     columns=['æ—¥æœŸ', 'æ•°é‡'])
    fig = px.line(df, x='æ—¥æœŸ', y='æ•°é‡',
                  title='è¯„è®ºæ•°é‡è¶‹åŠ¿',
                  labels={'æ—¥æœŸ': 'æ—¥æœŸ', 'æ•°é‡': 'è¯„è®ºæ•°é‡'})
    st.plotly_chart(fig)

def show_keyword_analysis(df: pd.DataFrame, language: str):
    """
    æ˜¾ç¤ºå…³é”®è¯åˆ†æé¡µé¢
    
    Args:
        df: æ•°æ®æ¡†
        language: æ–‡æœ¬è¯­è¨€
    """
    st.header("å…³é”®è¯åˆ†æ")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    keyword_analyzer = KeywordAnalyzer(language)
    keyword_visualizer = KeywordVisualizer()
    
    # åˆ†æè®¾ç½®
    col1, col2 = st.columns(2)
    with col1:
        top_n = st.slider(
            "æ˜¾ç¤ºå…³é”®è¯æ•°é‡",
            5, 50, 20,
            key="keyword_analysis_count_slider"
        )
    with col2:
        time_window = st.selectbox(
            "æ—¶é—´çª—å£",
            options=[("æ—¥", "D"), ("å‘¨", "W"), ("æœˆ", "M")],
            format_func=lambda x: x[0],
            index=1,
            key="keyword_analysis_time_window"
        )[1]
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["è¯äº‘å›¾", "å…³é”®è¯è¶‹åŠ¿", "è¯„åˆ†å…³é”®è¯å¯¹æ¯”"])
    
    with tab1:
        st.subheader("è¯äº‘åˆ†æ")
        if st.button("ç”Ÿæˆè¯äº‘", key="keyword_analysis_wordcloud_button"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆè¯äº‘..."):
                # æå–å…³é”®è¯
                texts = df['content'].tolist()
                keywords = keyword_analyzer.extract_keywords(texts, top_n)
                
                # ç”Ÿæˆè¯äº‘å›¾
                st.plotly_chart(
                    keyword_visualizer.create_wordcloud(keywords),
                    use_container_width=True
                )
    
    with tab2:
        st.subheader("å…³é”®è¯è¶‹åŠ¿åˆ†æ")
        if st.button("åˆ†æè¶‹åŠ¿", key="keyword_analysis_trend_button"):
            with st.spinner("æ­£åœ¨åˆ†æè¶‹åŠ¿..."):
                # è·å–æ•´ä½“å…³é”®è¯
                all_keywords = keyword_analyzer.extract_keywords(
                    df['content'].tolist(),
                    top_n=10
                )
                
                # è®¡ç®—è¶‹åŠ¿
                trend_df = keyword_analyzer.calculate_keyword_trends(
                    df,
                    list(all_keywords.keys()),
                    time_window
                )
                
                # æ˜¾ç¤ºè¶‹åŠ¿å›¾
                st.plotly_chart(
                    keyword_visualizer.create_keyword_trend_chart(trend_df),
                    use_container_width=True
                )
    
    with tab3:
        st.subheader("è¯„åˆ†å…³é”®è¯å¯¹æ¯”")
        if st.button("åˆ†æè¯„åˆ†å…³é”®è¯", key="keyword_analysis_rating_button"):
            with st.spinner("æ­£åœ¨åˆ†æè¯„åˆ†å…³é”®è¯..."):
                # æŒ‰è¯„åˆ†æå–å…³é”®è¯
                keywords_by_rating = keyword_analyzer.extract_keywords_by_rating(
                    df,
                    top_n=10
                )
                
                # æ˜¾ç¤ºå¯¹æ¯”å›¾
                st.plotly_chart(
                    keyword_visualizer.create_rating_keyword_comparison(keywords_by_rating),
                    use_container_width=True
                )
                
                # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("##### é«˜åˆ†è¯„ä»·å¸¸è§å…³é”®è¯")
                    for word, weight in keywords_by_rating['positive'].items():
                        st.write(f"- {word}: {weight:.4f}")
                
                with col2:
                    st.markdown("##### ä½åˆ†è¯„ä»·å¸¸è§å…³é”®è¯")
                    for word, weight in keywords_by_rating['negative'].items():
                        st.write(f"- {word}: {weight:.4f}")

def show_topic_analysis(df: pd.DataFrame, language: str):
    """
    æ˜¾ç¤ºä¸»é¢˜åˆ†æé¡µé¢
    
    Args:
        df: æ•°æ®æ¡†
        language: æ–‡æœ¬è¯­è¨€
    """
    st.header("ä¸»é¢˜èšç±»åˆ†æ")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    topic_analyzer = TopicAnalyzer(language)
    topic_visualizer = TopicVisualizer()
    
    # é…ç½®åŒº
    col1, col2, col3 = st.columns(3)
    with col1:
        n_topics = st.slider("ä¸»é¢˜æ•°é‡", 3, 10, 5)
    with col2:
        method = st.selectbox(
            "åˆ†ææ–¹æ³•", 
            options=[("LDAä¸»é¢˜æ¨¡å‹", "lda"), ("KMeansèšç±»", "kmeans")],
            format_func=lambda x: x[0],
            index=0
        )[1]
    with col3:
        time_window = st.selectbox(
            "æ—¶é—´çª—å£",
            options=[("æ—¥", "D"), ("å‘¨", "W"), ("æœˆ", "M")],
            format_func=lambda x: x[0],
            index=1
        )[1]
    
    # åˆ†æç»“æœå±•ç¤º
    tab1, tab2, tab3, tab4 = st.tabs([
        "ä¸»é¢˜åˆ†å¸ƒ",
        "ä¸»é¢˜ç½‘ç»œ",
        "ä¸»é¢˜çƒ­åŠ›å›¾",
        "ä¸»é¢˜è¶‹åŠ¿"
    ])
    
    if st.button("å¼€å§‹åˆ†æ", key="start_topic_analysis"):
        with st.spinner("æ­£åœ¨è¿›è¡Œä¸»é¢˜åˆ†æ..."):
            # è·å–æ–‡æœ¬æ•°æ®
            texts = df['content'].tolist()
            
            # æ‰§è¡Œä¸»é¢˜åˆ†æ
            topic_results = topic_analyzer.analyze_topics(
                texts,
                n_topics=n_topics,
                method=method
            )
            
            if topic_results:
                # ä¸»é¢˜åˆ†å¸ƒ
                with tab1:
                    st.subheader("ä¸»é¢˜åˆ†å¸ƒåˆ†æ")
                    st.plotly_chart(
                        topic_visualizer.create_topic_distribution(topic_results),
                        use_container_width=True
                    )
                    
                    # æ˜¾ç¤ºä¸»é¢˜å…³é”®è¯
                    st.subheader("ä¸»é¢˜å…³é”®è¯")
                    for i, keywords in enumerate(topic_results['topics']):
                        with st.expander(f"ä¸»é¢˜ {i+1}"):
                            st.write("å…³é”®è¯ï¼š" + ", ".join(keywords))
                            if 'example_docs' in topic_results:
                                st.write("ç¤ºä¾‹æ–‡æ¡£ï¼š")
                                for doc in topic_results['example_docs'].get(i, []):
                                    st.markdown(f"> {doc}")
                
                # ä¸»é¢˜ç½‘ç»œ
                with tab2:
                    st.subheader("ä¸»é¢˜-å…³é”®è¯ç½‘ç»œå›¾")
                    st.plotly_chart(
                        topic_visualizer.create_topic_network(topic_results),
                        use_container_width=True
                    )
                
                # ä¸»é¢˜çƒ­åŠ›å›¾
                with tab3:
                    st.subheader("ä¸»é¢˜åˆ†å¸ƒçƒ­åŠ›å›¾")
                    if 'topic_distribution' in topic_results:
                        topic_dist_df = pd.DataFrame(
                            topic_results['topic_distribution'],
                            columns=[f"ä¸»é¢˜{i+1}" for i in range(n_topics)]
                        )
                        st.plotly_chart(
                            topic_visualizer.create_topic_heatmap(topic_dist_df),
                            use_container_width=True
                        )
                    else:
                        st.info("å½“å‰åˆ†ææ–¹æ³•ä¸æ”¯æŒä¸»é¢˜åˆ†å¸ƒçƒ­åŠ›å›¾")
                
                # ä¸»é¢˜è¶‹åŠ¿
                with tab4:
                    st.subheader("ä¸»é¢˜è¶‹åŠ¿åˆ†æ")
                    trend_df = topic_analyzer.get_topic_trends(
                        df,
                        topic_results['document_topics'],
                        time_window
                    )
                    
                    if not trend_df.empty:
                        st.plotly_chart(
                            topic_visualizer.create_topic_trend(trend_df),
                            use_container_width=True
                        )
                    else:
                        st.warning("æ— æ³•ç”Ÿæˆä¸»é¢˜è¶‹åŠ¿å›¾ï¼Œå¯èƒ½æ˜¯æ•°æ®é‡ä¸è¶³")
                
                # ä¸‹è½½åˆ†æç»“æœ
                if st.download_button(
                    "ä¸‹è½½åˆ†æç»“æœ",
                    data=pd.DataFrame({
                        'text': texts,
                        'topic': topic_results['document_topics']
                    }).to_csv(index=False),
                    file_name="topic_analysis_results.csv",
                    mime="text/csv"
                ):
                    st.success("åˆ†æç»“æœå·²ä¸‹è½½")

# def show_insights_analysis(df: pd.DataFrame, language: str):
#     """
#     æ˜¾ç¤ºè¯„è®ºæ´å¯Ÿåˆ†æé¡µé¢
    
#     Args:
#         df: æ•°æ®æ¡†
#         language: æ–‡æœ¬è¯­è¨€
#     """
#     st.header("è¯„è®ºæ·±åº¦æ´å¯Ÿ")
    
#     # åˆå§‹åŒ–åˆ†æå™¨
#     insight_analyzer = InsightAnalyzer(language)
#     insight_visualizer = InsightVisualizer()
    
#     if st.button("å¼€å§‹åˆ†æ", key="start_insight_analysis"):
#         with st.spinner("æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ..."):
#             # æå–æ´å¯Ÿ
#             insights = insight_analyzer.extract_insights(df)
            
#             if insights:
#                 # æ˜¾ç¤ºå¼‚å¸¸æ£€æµ‹ç»“æœ
#                 st.subheader("å¼‚å¸¸è¯„è®ºæ£€æµ‹")
                
#                 # æ˜¾ç¤ºå¼‚å¸¸ç»Ÿè®¡
#                 col1, col2 = st.columns(2)
#                 with col1:
#                     st.metric(
#                         "å¼‚å¸¸è¯„è®ºæ•°é‡",
#                         insights['anomalies']['total']
#                     )
#                 with col2:
#                     st.metric(
#                         "å¼‚å¸¸è¯„è®ºæ¯”ä¾‹",
#                         f"{insights['anomalies']['total']/len(df):.1%}"
#                     )
                
#                 # æ˜¾ç¤ºå¼‚å¸¸æ•£ç‚¹å›¾
#                 st.plotly_chart(
#                     insight_visualizer.create_anomaly_scatter(df),
#                     use_container_width=True
#                 )
                
#                 # æ˜¾ç¤ºç›¸å…³æ€§åˆ†æ
#                 st.subheader("ç›¸å…³æ€§åˆ†æ")
#                 if insights.get('correlations'):
#                     st.metric(
#                         "è¯„åˆ†-æƒ…æ„Ÿç›¸å…³æ€§",
#                         f"{insights['correlations']['correlation']:.2f}"
#                     )
#                     st.metric(
#                         "è¯„åˆ†-æƒ…æ„Ÿä¸€è‡´æ€§",
#                         f"{insights['correlations']['consistency']:.1%}"
#                     )


def show_insights_analysis(df: pd.DataFrame, language: str):
    """
    æ˜¾ç¤ºè¯„è®ºæ´å¯Ÿåˆ†æé¡µé¢
    
    Args:
        df: æ•°æ®æ¡†
        language: æ–‡æœ¬è¯­è¨€
    """
    st.header("è¯„è®ºæ·±åº¦æ´å¯Ÿ")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    insight_analyzer = InsightAnalyzer(language)
    insight_visualizer = InsightVisualizer()
    
    if st.button("å¼€å§‹åˆ†æ", key="start_insight_analysis"):
        with st.spinner("æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ..."):
            # æå–æ´å¯Ÿ
            insights = insight_analyzer.extract_insights(df)
            
            if insights and 'anomalies' in insights:
                # æ˜¾ç¤ºå¼‚å¸¸æ£€æµ‹ç»“æœ
                st.subheader("å¼‚å¸¸è¯„è®ºæ£€æµ‹")
                
                # æ˜¾ç¤ºå¼‚å¸¸ç»Ÿè®¡
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        "å¼‚å¸¸è¯„è®ºæ•°é‡",
                        insights['anomalies']['total']
                    )
                with col2:
                    st.metric(
                        "å¼‚å¸¸è¯„è®ºæ¯”ä¾‹",
                        f"{insights['anomalies']['total']/len(df):.1%}"
                    )
                
                # æ˜¾ç¤ºå¼‚å¸¸æ•£ç‚¹å›¾ - ä½¿ç”¨å¸¦æœ‰å¼‚å¸¸æ ‡è®°çš„å®Œæ•´DataFrame
                if 'df' in insights['anomalies']:
                    st.plotly_chart(
                        insight_visualizer.create_anomaly_scatter(insights['anomalies']['df']),
                        use_container_width=True
                    )
                
                # æ˜¾ç¤ºç›¸å…³æ€§åˆ†æ
                st.subheader("ç›¸å…³æ€§åˆ†æ")
                if insights.get('correlations'):
                    st.metric(
                        "è¯„åˆ†-æƒ…æ„Ÿç›¸å…³æ€§",
                        f"{insights['correlations']['correlation']:.2f}"
                    )
                    st.metric(
                        "è¯„åˆ†-æƒ…æ„Ÿä¸€è‡´æ€§",
                        f"{insights['correlations']['consistency']:.1%}"
                    )



def create_custom_visualizations(df: pd.DataFrame):
    """åˆ›å»ºè‡ªå®šä¹‰å¯è§†åŒ–å›¾è¡¨"""
    # å›¾è¡¨ç±»å‹é€‰æ‹©
    chart_type = st.selectbox(
        "é€‰æ‹©å›¾è¡¨ç±»å‹",
        ["æ—¶é—´åºåˆ—å›¾", "è¯„åˆ†åˆ†å¸ƒå›¾", "æ–‡æœ¬é•¿åº¦åˆ†å¸ƒå›¾", "è‡ªå®šä¹‰åˆ†ç»„ç»Ÿè®¡"]
    )
    
    # æ ¹æ®é€‰æ‹©çš„å›¾è¡¨ç±»å‹æ˜¾ç¤ºä¸åŒçš„é€‰é¡¹å’Œå›¾è¡¨
    if chart_type == "æ—¶é—´åºåˆ—å›¾":
        # æ—¶é—´ç²’åº¦é€‰æ‹©
        time_unit = st.selectbox(
            "é€‰æ‹©æ—¶é—´ç²’åº¦",
            ["æ—¥", "å‘¨", "æœˆ"],
            key="time_series_unit"
        )
        
        # é€‰æ‹©è¦å±•ç¤ºçš„æŒ‡æ ‡
        metrics = st.multiselect(
            "é€‰æ‹©è¦å±•ç¤ºçš„æŒ‡æ ‡",
            ["è¯„è®ºæ•°é‡", "å¹³å‡è¯„åˆ†", "å¹³å‡æ–‡æœ¬é•¿åº¦"],
            default=["è¯„è®ºæ•°é‡"]
        )
        
        # åˆ›å»ºæ—¶é—´åºåˆ—å›¾è¡¨
        try:
            # è®¾ç½®æ—¶é—´ç´¢å¼•
            df['date'] = pd.to_datetime(df['timestamp']).dt.date
            if time_unit == "å‘¨":
                df['date'] = pd.to_datetime(df['timestamp']).dt.to_period('W').astype(str)
            elif time_unit == "æœˆ":
                df['date'] = pd.to_datetime(df['timestamp']).dt.to_period('M').astype(str)
            
            # å‡†å¤‡æ•°æ®
            fig = go.Figure()
            
            if "è¯„è®ºæ•°é‡" in metrics:
                counts = df.groupby('date').size()
                fig.add_trace(go.Scatter(
                    x=counts.index, 
                    y=counts.values,
                    name="è¯„è®ºæ•°é‡",
                    mode='lines+markers'
                ))
            
            if "å¹³å‡è¯„åˆ†" in metrics:
                avg_ratings = df.groupby('date')['rating'].mean()
                fig.add_trace(go.Scatter(
                    x=avg_ratings.index,
                    y=avg_ratings.values,
                    name="å¹³å‡è¯„åˆ†",
                    mode='lines+markers',
                    yaxis="y2"
                ))
            
            if "å¹³å‡æ–‡æœ¬é•¿åº¦" in metrics:
                avg_lengths = df.groupby('date')['text_length'].mean()
                fig.add_trace(go.Scatter(
                    x=avg_lengths.index,
                    y=avg_lengths.values,
                    name="å¹³å‡æ–‡æœ¬é•¿åº¦",
                    mode='lines+markers',
                    yaxis="y3"
                ))
            
            # æ›´æ–°å¸ƒå±€
            fig.update_layout(
                title="æ—¶é—´åºåˆ—è¶‹åŠ¿å›¾",
                xaxis_title="æ—¥æœŸ",
                yaxis_title="è¯„è®ºæ•°é‡",
                yaxis2=dict(
                    title="å¹³å‡è¯„åˆ†",
                    overlaying="y",
                    side="right"
                ),
                yaxis3=dict(
                    title="å¹³å‡æ–‡æœ¬é•¿åº¦",
                    overlaying="y",
                    side="right",
                    position=0.95
                )
            )
            
            st.plotly_chart(fig)
            
        except Exception as e:
            st.error(f"ç”Ÿæˆæ—¶é—´åºåˆ—å›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
    
    elif chart_type == "è¯„åˆ†åˆ†å¸ƒå›¾":
        # å›¾è¡¨å­ç±»å‹é€‰æ‹©
        subtype = st.selectbox(
            "é€‰æ‹©å›¾è¡¨å­ç±»å‹",
            ["æŸ±çŠ¶å›¾", "é¥¼å›¾", "ç®±çº¿å›¾"],
            key="rating_dist_type"
        )
        
        try:
            if subtype == "æŸ±çŠ¶å›¾":
                rating_counts = df['rating'].value_counts().sort_index()
                fig = px.bar(
                    x=rating_counts.index,
                    y=rating_counts.values,
                    title="è¯„åˆ†åˆ†å¸ƒ",
                    labels={'x': 'è¯„åˆ†', 'y': 'æ•°é‡'}
                )
                
            elif subtype == "é¥¼å›¾":
                rating_counts = df['rating'].value_counts()
                fig = px.pie(
                    values=rating_counts.values,
                    names=rating_counts.index,
                    title="è¯„åˆ†å æ¯”"
                )
                
            elif subtype == "ç®±çº¿å›¾":
                fig = px.box(
                    df,
                    y="rating",
                    title="è¯„åˆ†åˆ†å¸ƒç®±çº¿å›¾"
                )
            
            st.plotly_chart(fig)
            
        except Exception as e:
            st.error(f"ç”Ÿæˆè¯„åˆ†åˆ†å¸ƒå›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
    
    elif chart_type == "æ–‡æœ¬é•¿åº¦åˆ†å¸ƒå›¾":
        # é€‰æ‹©åˆ†ç»„æ•°
        num_bins = st.slider("é€‰æ‹©åˆ†ç»„æ•°", 10, 50, 20)
        
        try:
            fig = px.histogram(
                df,
                x="text_length",
                nbins=num_bins,
                title="æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ",
                labels={'text_length': 'æ–‡æœ¬é•¿åº¦', 'count': 'æ•°é‡'}
            )
            
            st.plotly_chart(fig)
            
        except Exception as e:
            st.error(f"ç”Ÿæˆæ–‡æœ¬é•¿åº¦åˆ†å¸ƒå›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
    
    elif chart_type == "è‡ªå®šä¹‰åˆ†ç»„ç»Ÿè®¡":
        # é€‰æ‹©åˆ†ç»„å­—æ®µ
        group_col = st.selectbox(
            "é€‰æ‹©åˆ†ç»„å­—æ®µ",
            ["category", "rating", "sentiment"],
            key="custom_group_col"
        )
        
        # é€‰æ‹©ç»Ÿè®¡æŒ‡æ ‡
        agg_metric = st.selectbox(
            "é€‰æ‹©ç»Ÿè®¡æŒ‡æ ‡",
            ["æ•°é‡", "å¹³å‡æ–‡æœ¬é•¿åº¦", "å¹³å‡æƒ…æ„Ÿå¾—åˆ†"],
            key="custom_agg_metric"
        )
        
        try:
            if agg_metric == "æ•°é‡":
                counts = df[group_col].value_counts()
                fig = px.bar(
                    x=counts.index,
                    y=counts.values,
                    title=f"æŒ‰{group_col}åˆ†ç»„çš„è¯„è®ºæ•°é‡",
                    labels={'x': group_col, 'y': 'æ•°é‡'}
                )
                
            elif agg_metric == "å¹³å‡æ–‡æœ¬é•¿åº¦":
                avg_lengths = df.groupby(group_col)['text_length'].mean()
                fig = px.bar(
                    x=avg_lengths.index,
                    y=avg_lengths.values,
                    title=f"æŒ‰{group_col}åˆ†ç»„çš„å¹³å‡æ–‡æœ¬é•¿åº¦",
                    labels={'x': group_col, 'y': 'å¹³å‡é•¿åº¦'}
                )
                
            elif agg_metric == "å¹³å‡æƒ…æ„Ÿå¾—åˆ†":
                avg_sentiment = df.groupby(group_col)['sentiment_score'].mean()
                fig = px.bar(
                    x=avg_sentiment.index,
                    y=avg_sentiment.values,
                    title=f"æŒ‰{group_col}åˆ†ç»„çš„å¹³å‡æƒ…æ„Ÿå¾—åˆ†",
                    labels={'x': group_col, 'y': 'å¹³å‡æƒ…æ„Ÿå¾—åˆ†'}
                )
            
            st.plotly_chart(fig)
            
        except Exception as e:
            st.error(f"ç”Ÿæˆè‡ªå®šä¹‰åˆ†ç»„ç»Ÿè®¡å›¾è¡¨æ—¶å‡ºé”™: {str(e)}")


def main():
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="é¡¾å®¢è¯„è®ºåˆ†æç³»ç»Ÿ",
        page_icon="ğŸ“Š",
        layout="wide"
    )

        # åˆå§‹åŒ–jieba
    try:
        initialize_jieba()
    except Exception as e:
        st.error(f"jiebaåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return
    
    # é¡µé¢é—®é¢˜
    st.title("é¡¾å®¢è¯„è®ºåˆ†æç³»ç»Ÿ")
    st.markdown("### æ™ºèƒ½åˆ†ææ‚¨çš„é¡¾å®¢è¯„è®ºæ•°æ®")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    data_processor = DataProcessor()
    
    # ä¾§è¾¹
    with st.sidebar:
        st.header("é…ç½®é€‰é¡¹")
        language = st.selectbox(
            "é€‰æ‹©è¯„è®ºè¯­è¨€",
            ["ä¸­æ–‡", "è‹±æ–‡", "åŒè¯­"]
        )
        
        analysis_options = st.multiselect(
            "é€‰æ‹©åˆ†æç»´åº¦",
            options=["æƒ…æ„Ÿåˆ†æ", "å…³é”®è¯åˆ†æ", "ä¸»é¢˜èšç±»", "è¯„åˆ†ç»Ÿè®¡"],
            default=["æƒ…æ„Ÿåˆ†æ", "å…³é”®è¯åˆ†æ"]
        )
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    tabs = st.tabs(["æ•°æ®ä¸Šä¼ ", "æƒ…æ„Ÿåˆ†æ", "å…³é”®è¯åˆ†æ", "ä¸»é¢˜åˆ†æ", "æ´å¯Ÿåˆ†æ", "å¯è§†åŒ–å±•ç¤º"])
    
    with tabs[0]:
        st.header("æ•°æ®ä¸Šä¼ ")
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶",
            type=["csv", "xlsx"]
        )
        
        if uploaded_file is not None:
            try:
                # è¯»å–CSVæ–‡ä»¶
                df = pd.read_csv(uploaded_file)
                
                # éªŒè¯å¿…éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨
                required_columns = ['timestamp', 'content']
                missing_columns = [col for col in required_columns if col not in df.columns]
                
                if missing_columns:
                    st.error(f"CSVæ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„åˆ—: {', '.join(missing_columns)}")
                    st.info("è¯·ç¡®ä¿CSVæ–‡ä»¶åŒ…å«ä»¥ä¸‹åˆ—ï¼štimestampï¼ˆæ—¶é—´æˆ³ï¼‰å’Œcontentï¼ˆæ–‡æœ¬å†…å®¹ï¼‰")
                    return
                
                # è½¬æ¢æ—¶é—´æˆ³ä¸ºdatetimeæ ¼å¼
                try:
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
                except Exception as e:
                    st.error(f"æ—¶é—´æˆ³æ ¼å¼è½¬æ¢å¤±è´¥ï¼š{str(e)}")
                    st.info("è¯·ç¡®ä¿timestampåˆ—çš„æ ¼å¼ä¸ºæ ‡å‡†æ—¥æœŸæ—¶é—´æ ¼å¼")
                    return
                
                # åˆå§‹åŒ– filtered_df
                filtered_df = df.copy()
                
                # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                st.subheader("æ•°æ®é¢„è§ˆ")
                st.write(df.head())
                
                # æ•°æ®ç­›é€‰éƒ¨åˆ†
                st.subheader("æ•°æ®ç­›é€‰")
                
                # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    # æ—¶é—´èŒƒå›´ç­›é€‰
                    st.write("æ—¶é—´èŒƒå›´ç­›é€‰")
                    min_date = df['timestamp'].min().date()
                    max_date = df['timestamp'].max().date()
                    
                    start_date = st.date_input(
                        "å¼€å§‹æ—¥æœŸ",
                        min_value=min_date,
                        max_value=max_date,
                        value=min_date
                    )
                    
                    end_date = st.date_input(
                        "ç»“æŸæ—¥æœŸ",
                        min_value=min_date,
                        max_value=max_date,
                        value=max_date
                    )
                
                with col2:
                    # è¯„åˆ†ç­›é€‰ï¼ˆå¦‚æœå­˜åœ¨è¯„åˆ†åˆ—ï¼‰
                    if 'rating' in df.columns:
                        st.write("è¯„åˆ†ç­›é€‰")
                        min_rating = float(df['rating'].min())
                        max_rating = float(df['rating'].max())
                        
                        rating_range = st.slider(
                            "é€‰æ‹©è¯„åˆ†èŒƒå›´",
                            min_value=min_rating,
                            max_value=max_rating,
                            value=(min_rating, max_rating),
                            step=0.5
                        )
                
                with col3:
                    # æ–‡æœ¬é•¿åº¦ç­›é€‰
                    st.write("æ–‡æœ¬é•¿åº¦ç­›é€‰")
                    df['text_length'] = df['content'].str.len()
                    min_length = int(df['text_length'].min())
                    max_length = int(df['text_length'].max())
                    
                    length_range = st.slider(
                        "é€‰æ‹©æ–‡æœ¬é•¿åº¦èŒƒå›´",
                        min_value=min_length,
                        max_value=max_length,
                        value=(min_length, max_length)
                    )
                
                # å…³é”®è¯æœç´¢
                search_term = st.text_input("æœç´¢å…³é”®è¯ï¼ˆæ”¯æŒå¤šä¸ªå…³é”®è¯ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼‰")
                
                # åº”ç”¨ç­›é€‰æ¡ä»¶
                filtered_df = df.copy()
                
                # æ—¶é—´ç­›é€‰
                filtered_df = filtered_df[
                    (filtered_df['timestamp'].dt.date >= start_date) &
                    (filtered_df['timestamp'].dt.date <= end_date)
                ]
                
                # è¯„åˆ†ç­›é€‰
                if 'rating' in df.columns:
                    filtered_df = filtered_df[
                        (filtered_df['rating'] >= rating_range[0]) &
                        (filtered_df['rating'] <= rating_range[1])
                    ]
                
                # æ–‡æœ¬é•¿åº¦ç­›é€‰
                filtered_df = filtered_df[
                    (filtered_df['text_length'] >= length_range[0]) &
                    (filtered_df['text_length'] <= length_range[1])
                ]
                
                # å…³é”®è¯æœç´¢
                if search_term:
                    keywords = search_term.split()
                    search_mask = filtered_df['content'].str.contains('|'.join(keywords), case=False, na=False)
                    filtered_df = filtered_df[search_mask]
                
                # æ˜¾ç¤ºç­›é€‰åçš„æ•°æ®ç»Ÿè®¡
                st.subheader("ç­›é€‰ç»“æœç»Ÿè®¡")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric(
                        "ç­›é€‰åæ•°æ®é‡",
                        f"{len(filtered_df)} æ¡",
                        f"å æ¯” {len(filtered_df)/len(df):.1%}"
                    )
                
                with col2:
                    if 'rating' in filtered_df.columns:
                        st.metric(
                            "å¹³å‡è¯„åˆ†",
                            f"{filtered_df['rating'].mean():.1f}",
                            f"åŸå‡åˆ† {df['rating'].mean():.1f}"
                        )
                
                # æ˜¾ç¤ºç­›é€‰åçš„æ•°æ®é¢„è§ˆ
                st.subheader("ç­›é€‰åçš„æ•°æ®é¢„è§ˆ")
                st.write(filtered_df.head())
                
                # æ·»åŠ ä¸‹è½½ç­›é€‰åçš„æ•°æ®åŠŸèƒ½
                if st.download_button(
                    "ä¸‹è½½ç­›é€‰åçš„æ•°æ®",
                    data=filtered_df.to_csv(index=False),
                    file_name="filtered_data.csv",
                    mime="text/csv"
                ):
                    st.success("æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                
            except Exception as e:
                st.error(f"å¤„ç†CSVæ–‡ä»¶æ—¶å‡ºç°é”™è¯¯: {str(e)}")
                st.info("è¯·ç¡®ä¿CSVæ–‡ä»¶æ ¼å¼æ­£ç¡®, å¹¶ä¸”åŒ…å«æ‰€éœ€çš„åˆ—")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    sentiment_analyzer = SentimentAnalyzer(language)
    sentiment_visualizer = SentimentVisualizer()
    
    with tabs[1]:
        st.header("æƒ…æ„Ÿåˆ†æ")
        if 'df' not in locals():
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        else:
            try:
                # åˆå§‹åŒ–åˆ†æå™¨
                sentiment_analyzer = SentimentAnalyzer(language)
                sentiment_visualizer = SentimentVisualizer()
                
                # æƒ…æ„Ÿåˆ†æè®¾ç½®
                st.subheader("åˆ†æè®¾ç½®")
                batch_size = st.slider("æ‰¹å¤„ç†å¤§å°", 16, 64, 32)
                
                if st.button("å¼€å§‹åˆ†æ"):
                    # æ˜¾ç¤ºè¿›åº¦æ¡
                    progress_text = st.empty()
                    progress_bar = st.progress(0)
                    
                    try:
                        # æ‰§è¡Œæƒ…æ„Ÿåˆ†æ
                        texts = filtered_df['content'].tolist()
                        sentiment_results = SentimentAnalyzer.cached_analyze_batch(
                            texts=texts,
                            model_name=sentiment_analyzer.model_name,
                            device=str(sentiment_analyzer.device),
                            language=language,
                            batch_size=batch_size
                        )
                        
                        # æ›´æ–°DataFrame
                        filtered_df['sentiment'] = [r['sentiment'] for r in sentiment_results]
                        filtered_df['confidence'] = [r['confidence'] for r in sentiment_results]
                        
                        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                        sentiment_stats = sentiment_analyzer.get_sentiment_stats(sentiment_results)
                        
                        # æ˜¾ç¤ºç»“æœ
                        st.subheader("åˆ†æç»“æœ")
                        
                        # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric(
                                "æ­£é¢è¯„è®ºæ¯”ä¾‹",
                                f"{sentiment_stats['sentiment_distribution'].get('æ­£é¢', 0) / len(sentiment_results):.1%}"
                            )
                        with col2:
                            st.metric(
                                "è´Ÿé¢è¯„è®ºæ¯”ä¾‹",
                                f"{sentiment_stats['sentiment_distribution'].get('è´Ÿé¢', 0) / len(sentiment_results):.1%}"
                            )
                        with col3:
                            st.metric(
                                "å¹³å‡ç½®ä¿¡åº¦",
                                f"{sentiment_stats['average_confidence']:.2f}"
                            )
                        
                        # æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ
                        st.plotly_chart(
                            sentiment_visualizer.create_sentiment_distribution(sentiment_results)
                        )
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.plotly_chart(
                                sentiment_visualizer.create_sentiment_trend(filtered_df)
                            )
                        with col2:
                            st.plotly_chart(
                                sentiment_visualizer.create_rating_sentiment_comparison(filtered_df)
                            )
                        
                        # æ˜¾ç¤ºå…¸å‹è¯„è®º
                        st.subheader("å…¸å‹è¯„è®ºç¤ºä¾‹")
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("##### å…¸å‹æ­£é¢è¯„è®º")
                            for comment in sentiment_stats['typical_positive']:
                                st.markdown(f"""
                                > {comment['text']}  
                                > ç½®ä¿¡åº¦ï¼š{comment['confidence']:.2f}
                                """)
                        
                        with col2:
                            st.markdown("##### å…¸å‹è´Ÿé¢è¯„è®º")
                            for comment in sentiment_stats['typical_negative']:
                                st.markdown(f"""
                                > {comment['text']}  
                                > ç½®ä¿¡åº¦ï¼š{comment['confidence']:.2f}
                                """)
                        
                    except Exception as e:
                        st.error(f"æƒ…æ„Ÿåˆ†æè¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")
            except Exception as e:
                st.error(f"åˆå§‹åŒ–æƒ…æ„Ÿåˆ†æå™¨æ—¶å‡ºé”™ï¼š{str(e)}")
    
    with tabs[2]:
        if 'df' not in locals():
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        else:
            try:
                # åœ¨è¿™é‡Œè°ƒç”¨ show_keyword_analysisï¼Œå¹¶æ·»åŠ éšæœºåç¼€ä»¥ç¡®ä¿ key å”¯ä¸€
                import random
                import string
                random_suffix = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
                show_keyword_analysis_with_unique_keys(filtered_df, language, random_suffix)
            except Exception as e:
                st.error(f"å…³é”®è¯åˆ†æè¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")
    
    with tabs[3]:
        if 'df' not in locals():
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        else:
            try:
                show_topic_analysis(filtered_df, language)
            except Exception as e:
                st.error(f"ä¸»é¢˜åˆ†æè¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")
    
    with tabs[4]:
        if 'df' not in locals():
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        else:
            try:
                show_insights_analysis(filtered_df, language)
            except Exception as e:
                st.error(f"æ´å¯Ÿåˆ†æè¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")
    
    with tabs[5]:
        st.header("å¯è§†åŒ–å±•ç¤º")
        if 'df' not in locals():
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        else:
            try:
                st.subheader("è‡ªå®šä¹‰å›¾è¡¨")
                create_custom_visualizations(filtered_df)
            except Exception as e:
                st.error(f"å¯è§†åŒ–è¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")

def show_keyword_analysis_with_unique_keys(df: pd.DataFrame, language: str, suffix: str):
    """
    æ˜¾ç¤ºå…³é”®è¯åˆ†æé¡µé¢ï¼ˆå¸¦æœ‰å”¯ä¸€çš„keyï¼‰
    
    Args:
        df: æ•°æ®æ¡†
        language: æ–‡æœ¬è¯­è¨€
        suffix: ç”¨äºç”Ÿæˆå”¯ä¸€keyçš„åç¼€
    """
    st.header("å…³é”®è¯åˆ†æ")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    keyword_analyzer = KeywordAnalyzer(language)
    keyword_visualizer = KeywordVisualizer()
    
    # åˆ†æè®¾ç½®
    col1, col2 = st.columns(2)
    with col1:
        top_n = st.slider(
            "æ˜¾ç¤ºå…³é”®è¯æ•°é‡",
            5, 50, 20,
            key=f"keyword_analysis_count_slider_{suffix}"
        )
    with col2:
        time_window = st.selectbox(
            "æ—¶é—´çª—å£",
            options=[("æ—¥", "D"), ("å‘¨", "W"), ("æœˆ", "M")],
            format_func=lambda x: x[0],
            index=1,
            key=f"keyword_analysis_time_window_{suffix}"
        )[1]
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["è¯äº‘å›¾", "å…³é”®è¯è¶‹åŠ¿", "è¯„åˆ†å…³é”®è¯å¯¹æ¯”"])
    
    with tab1:
        st.subheader("è¯äº‘åˆ†æ")
        if st.button("ç”Ÿæˆè¯äº‘", key=f"keyword_analysis_wordcloud_button_{suffix}"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆè¯äº‘..."):
                texts = df['content'].tolist()
                keywords = keyword_analyzer.extract_keywords(texts, top_n)
                st.plotly_chart(
                    keyword_visualizer.create_wordcloud(keywords),
                    use_container_width=True
                )
    
    with tab2:
        st.subheader("å…³é”®è¯è¶‹åŠ¿åˆ†æ")
        if st.button("åˆ†æè¶‹åŠ¿", key=f"keyword_analysis_trend_button_{suffix}"):
            with st.spinner("æ­£åœ¨åˆ†æè¶‹åŠ¿..."):
                all_keywords = keyword_analyzer.extract_keywords(
                    df['content'].tolist(),
                    top_n=10
                )
                trend_df = keyword_analyzer.calculate_keyword_trends(
                    df,
                    list(all_keywords.keys()),
                    time_window
                )
                st.plotly_chart(
                    keyword_visualizer.create_keyword_trend_chart(trend_df),
                    use_container_width=True
                )
    
    with tab3:
        st.subheader("è¯„åˆ†å…³é”®è¯å¯¹æ¯”")
        if st.button("åˆ†æè¯„åˆ†å…³é”®è¯", key=f"keyword_analysis_rating_button_{suffix}"):
            with st.spinner("æ­£åœ¨åˆ†æè¯„åˆ†å…³é”®è¯..."):
                keywords_by_rating = keyword_analyzer.extract_keywords_by_rating(
                    df,
                    top_n=10
                )
                st.plotly_chart(
                    keyword_visualizer.create_rating_keyword_comparison(keywords_by_rating),
                    use_container_width=True
                )
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("##### é«˜åˆ†è¯„ä»·å¸¸è§å…³é”®è¯")
                    for word, weight in keywords_by_rating['positive'].items():
                        st.write(f"- {word}: {weight:.4f}")
                
                with col2:
                    st.markdown("##### ä½åˆ†è¯„ä»·å¸¸è§å…³é”®è¯")
                    for word, weight in keywords_by_rating['negative'].items():
                        st.write(f"- {word}: {weight:.4f}")

if __name__ == "__main__":
    main() 